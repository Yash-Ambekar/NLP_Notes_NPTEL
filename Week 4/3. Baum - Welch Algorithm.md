-  Parameters of HMM are given by $\theta = (A,\ B, \, \pi)$  where,
	- $A = [a_{ij}] = P(X_t = j | X_{t-1} = i)$ -->  State Transition Matrix
	- $\pi = [\pi_{i}] = P(X_1 = i)$ -->  Initial State Distribution
	- $B = [b_j(y_t)] = P(y_t = y_t | X_t = j)$ -->  Emission Matrix
-  Given observation sequences $Y = (Y_1 = y_1, Y_2 = y_2,...., Y_T = y_T)$.
- This algorithm tries to find the parameters  $\theta$  that maximise the probability of the observation.

### Intuition 
-  The basic idea is start with some random initial conditions on the parameters $\theta$ , estimate best values of the state paths $X_t$   using these, then re-estimate the parameters  $\theta$  using the just-computed values of $X_t$ , iteratively.

### Algorithm
-  Choose some initial value for  $\theta = (A, B, \pi)$.
- Repeat the following step until convergence:
- Determine probable (state) paths  $... X_{t-1} = i,  \ X_t = j....$
-  Count the expected number of transitions  $a_{ij}$  as well as the expected number of times, various emissions $b_j(y_t)$  are made.
- Re-estimate $\theta = (A, B, \pi)$  as  $\overset{-}{\theta} = (\overset{-}{A}, \overset{-}{B}, \overset{-}{\pi})$   using $a_{ij}$  and $b_j(y_t)$ .
-  After getting all the parameters we can simply apply the Viterbi Decoding Algorithm to get the most probable sequence of POS tag.


### <font color = "Red">How do you compute probabilities of different state paths?</font>
#### Ans:  <font color = "green">Forward-Backward Algorithm</font> 


### Forward - Backward Algorithm

```mermaid
graph LR;
y_1---y_2 
y_2-.-y_t 
y_t---y_t+1 
y_t--tag-->X_t=i 
y_t+1-.-y_T-1 
y_T-1---y_T 
```
-  In the above graph, $Y = y_i$  are the observations and  $y_t --> X_t = i$  as the POS tag.


- In the **Forward Procedure**, we try to find  $$\alpha_i(t) = P(\ Y_1 = y_1, \ Y_2 = y_2 \ ...\ Y_t = y_t, \ X_t = i \ |\ \theta \ )$$
  here , we are trying to compute the probability of observations $Y_1 \; to \; Y_t$  and state(tag) $X_t = i$  to occur given the parameter $\theta$ . 
  i.e. this part of the above graph
```mermaid
graph LR;
y_1---y_2 
y_2-.-y_t
y_t--tag-->X_t=i 
```


-  In the **Backward Procedure**, we try to find $$\beta_i(t) = P(\ Y_{t+1} = y_{t+1} ,\ ...,\ Y_{T-1} = y_{T-1} ,\ Y_T = y_T\ |\ X_t = i ,\ \theta \ )$$
  here we are trying to compute the probability of observations $Y_{t+1} \; to \; Y_T$  occurring given the state(tag) $X_t = i$   and the parameter  $\theta$ . 
  i.e. this part of the first graph
  ```mermaid
graph LR;
y_t+1-.-y_T-1 
y_T-1---y_T 
```
-  It is called Backward Procedure as we will first calculate $\beta_i(T)$  and then move backwards to calculate $\beta_j(T-1)$ .

-  Now, the probability of $Y \ and \ X_t = i$  occurring is given by multiplying $\alpha_i(t)$  and  $\beta_i(t)$ . 
- To get the probability of we need to normalize this probability with summation of probability of all the possible tags at time $t$ . 
$$\frac{P(X_t = i \ , Y \ | \ \theta)}{\sum\limits_{j = 1}^{N} P(X_t = j \ , \ Y, \ | \ \theta)} = \frac{\alpha_i(t) \cdot  \beta_i(t)}{\sum\limits_{j=1}^N \alpha_j(t) \cdot \beta_j(t)}$$

  
  -  Lets compute $\alpha$  at  time  $t = 0$,
$$\alpha_i(1) = P(\ Y_1 = y_1, X_1 = i \ | \ \theta \ )= \pi_i \cdot b_i(y_1)$$

-  Similarly for computing  $\alpha$  at time  $t = t + 1$,$$ 
\begin{split}
\alpha_j(t + 1) &= P(Y_1 = y_1, Y_2 = y_2,\ ....\ ,Y_{t + 1},\ X_{t + 1} = j \ | \ \theta \ )\\\\
&= \sum\limits_{i=1}^N \alpha_i(t) \cdot a_{ij} \cdot b_j(y_{t+1})\\\\
& \boxed{\alpha_j(t + 1) = b_j(y_{t+1}) \cdot \sum\limits_{i=1}^N \alpha_i(t) \cdot a_{ij}}
\end{split}
$$
$$$$
$i$   is previous state from which it transitioned to state  $j$  . So above we used the previous state $\alpha_i(t)$ ,  $a_{ij}$  i.e. state transition probability and  $b_j(y_{t+1})$ i.e. emission probability  over all previous $N$ states to get  $\alpha_j(t+1)$ .


-  Lets compute $\beta$  at time $t = T$,
  $$
  \begin{split}
  \beta_i(T) &= P(Y_{T+1} = y_{T+1},\ ...., Y_{T^2} \ | X_T = i, \theta)\\\\ 
  &= P(\ null \ sequence \ | X_T = i, \theta)\\\\
  \beta_i(T) &= 1
  \end{split}
  $$

  -  Similarly we calculate $\beta$  at time $t = t$,
$$
\boxed{\beta_i(t) = \sum\limits_{j =1}^N \beta_j(t + 1) \cdot a_{ij} \cdot b_j(y_{t+1})}
$$
$j$  is the next state  from which $i$  transitions to.  In the above equation you can see that $\beta_j(t+1)$ is used to calculate $\beta_i(t)$  so it is clear that we are moving backwards. 
$a_{ij}$  is the transition probability and $b_j(y_{t+1})$  is the emission probability, we multiply these terms over all $N$ next states.


-  After calculating $\alpha$  and  $\beta$  we have to re-estimate the values of $a_{ij}$  and  $b_j(y_t)$ . For that we have to calculate $P(X_t = i \ | \ Y, \theta)$  and $P(X_t = i, X_{t+1} = j \ | \ Y, \theta)$  for the emission and transition probabilities respectively. 

-  We name these probabilities as,
$$\boxed{\gamma_i(t) = P( \ X_t = i \ |\ Y, \theta \ )}$$
$$\boxed {\zeta_{ij}(t) = P(\ X_t = i, X_{t+1} = j \ |\ Y, \theta)}$$
-  $\gamma _i(t)$  is the probability of being in state $i$  at time  $t$  given the observation $Y$ and parameters  $\theta$.
- $\zeta_{ij}(t)$  is the probability of being in state $i$  and state $j$  at time $t$  and $t+1$  respectively given the observation $Y$ and parameters $\theta$.
-  Now we have to find these probabilities using $\alpha$  and  $\beta$ .

$$\gamma_i(t) =  P( \ X_t = i \ |\ Y, \theta \ ) = \frac{P(X_t = i \ \cap Y \ \cap \ \theta)}{P(\ Y \ \cap \ \theta)} = \frac{P(X_t = i ,\ Y \ | \ \theta)}{P( \ Y \ | \ \theta)}$$
$$P(Y \ |\ \theta) =Normalizing \ factor$$
-  We already know that,
  $$\frac{P(X_t = i \ , Y \ | \ \theta)}{\sum\limits_{j = 1}^{N} P(X_t = j \ , \ Y, \ | \ \theta)} = \frac{\alpha_i(t) \cdot  \beta_i(t)}{\sum\limits_{j=1}^N \alpha_j(t) \cdot \beta_j(t)}$$
-  Therefore,
$$\boxed {\gamma_i(t) = \frac{\alpha_i(t) \cdot  \beta_i(t)}{\sum\limits_{j=1}^N \alpha_j(t) \cdot \beta_j(t)}}$$
 
  
  -  Lets follow the same steps to get $\zeta_{ij}(t)$  as well,
$$
\begin{split}
\zeta_{ij}(t) &= P(\ X_t = i, X_{t+1} = j \ |\ Y, \theta)\\\\
&= \frac{P(X_t = i \ \cap X_{t+1} = j \ \cap \ Y \ \cap \ \theta)}{P(Y \ \cap \ \theta)}\\\\
&= \frac{P(\ X_t = i, X_{t+1} = j, \ Y \ | \ \theta)}{P(\ Y \ | \ \theta)}
\end{split}
$$
$$P(Y \ | \ \theta) = Normalizing \ Factor$$


-  We can write $P(\ X_t = i, X_{t+1} = j, \ Y \ | \ \theta)$   as multiplication of 
	1.  $\alpha_i(t)$    i.e.    $P(\ Y_1 = y_1, \ Y_2 = y_2 \ ...\ Y_t = y_t, \ X_t = i \ |\ \theta \ )$
	2. $\beta_j(t + 1)$    i.e.    $P(\ Y_{t+1} = y_{t+1} ,\ ...,\ Y_{T-1} = y_{T-1} ,\ Y_T = y_T\ |\ X_t = i ,\ \theta \ )$
	3.  $a_{ij}$    i.e.    $P(X_{t+1} = j \ |\  X_t = i, \ \theta)$
	4.  $b_j(y_{t+1})$    i.e.    $P(Y_{t+1} = y_{t+1} \ | \ X_{t+1} = j, \ \theta)$

-  And we can normalize the above term by the summation of all the possible next and current POS tags denoted by  $i$  and  $j$.
$$Normalizing \ Factor = \sum\limits_{i}\sum\limits_{j} \alpha_i(t) \cdot \beta_j(t + 1) \cdot a_{ij} \cdot b_j(y_{t+1})$$
- So finally we get,
$$\boxed{\zeta_{ij}(t) = \frac{\alpha_i(t) \cdot \beta_j(t + 1) \cdot a_{ij} \cdot b_j(y_{t+1})}{\sum\limits_{i}\sum\limits_{j} \alpha_i(t) \cdot \beta_j(t + 1) \cdot a_{ij} \cdot b_j(y_{t+1})}}$$
