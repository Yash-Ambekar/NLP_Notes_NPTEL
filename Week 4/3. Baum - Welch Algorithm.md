-  Parameters of HMM are given by $\theta = (A,\ B, \, \pi)$  where,
	- $A = [a_{ij}] = P(X_t = j | X_{t-1} = i)$ -->  State Transition Matrix
	- $\pi = [\pi_{i}] = P(X_1 = i)$ -->  Initial State Distribution
	- $B = [b_j(y_t)] = P(y_t = y_t | X_t = j)$ -->  Emission Matrix
-  Given observation sequences $Y = (Y_1 = y_1, Y_2 = y_2,...., Y_T = y_T)$.
- This algorithm tries to find the parameters  $\theta$  that maximise the probability of the observation.

### Intuition 
-  The basic idea is start with some random initial conditions on the parameters $\theta$ , estimate best values of the state paths $X_t$   using these, then re-estimate the parameters  $\theta$  using the just-computed values of $X_t$ , iteratively.

### Algorithm
-  Choose some initial value for  $\theta = (A, B, \pi)$.
- Repeat the following step until convergence:
- Determine probable (state) paths  $... X_{t-1} = i,  \ X_t = j....$
-  Count the expected number of transitions  $a_{ij}$  as well as the expected number of times, various emissions $b_j(y_t)$  are made.
- Re-estimate   $\theta = (A, B, \pi)$  as  $\overset{-}{\theta} = (\overset{-}{A}, \overset{-}{B}, \overset{-}{\pi})$   using $a_{ij}$  and $b_j(y_t)$ .
-  After getting all the parameters we can simply apply the Viterbi Decoding Algorithm to get the most probable sequence of POS tag.


### <font color = "Red">How do you compute probabilities of different state paths?</font>
#### Ans:  <font color = "green">Forward-Backward Algorithm</font> 


### Forward - Backward Algorithm

```mermaid
graph LR;
y_1---y_2 
y_2-.-y_t 
y_t---y_t+1 
y_t--tag-->X_t=i 
y_t+1-.-y_T-1 
y_T-1---y_T 
```
-  In the above graph, $Y = y_i$  are the observations and  $y_t --> X_t = i$  as the POS tag.


- In the **Forward Procedure**, we try to find  $$\alpha_i(t) = P(\ Y_1 = y_1, \ Y_2 = y_2 \ ...\ Y_t = y_t, \ X_t = i \ |\ \theta \ )$$
  here , we are trying to compute the probability of observations $Y_1 \; to \; Y_t$  and state(tag) $X_t = i$  to occur given the parameter $\theta$ . 
  i.e. this part of the above graph
```mermaid
graph LR;
y_1---y_2 
y_2-.-y_t
y_t--tag-->X_t=i 
```


-  In the **Backward Procedure**, we try to find $$\beta_i(t) = P(\ Y_{t+1} = y_{t+1} ,\ ...,\ Y_{T-1} = y_{T-1} ,\ Y_T = y_T\ |\ X_t = i ,\ \theta \ )$$
  here we are trying to compute the probability of observations $Y_{t+1} \; to \; Y_T$  occurring given the state(tag) $X_t = i$   and the parameter  $\theta$ . 
  i.e. this part of the first graph
  ```mermaid
graph LR;
y_t+1-.-y_T-1 
y_T-1---y_T 
```
-  It is called Backward Procedure as we will first calculate $\beta_i(T)$  and then move backwards to calculate $\beta_j(T-1)$ .

-  Now, the probability of $Y \ and \ X_t = i$  occurring is given by multiplying $\alpha_i(t)$  and  $\beta_i(t)$ . 
- To get the probability of we need to normalize this probability with summation of probability of all the possible tags at time $t$ . 
$$\frac{P(X_t = i \ , Y \ | \ \theta)}{\sum\limits_{j = 1}^{N} P(X_t = j \ , \ Y, \ | \ \theta)} = \frac{\alpha_i(t) \cdot  \beta_i(t)}{\sum\limits_{j=1}^N \alpha_j(t) \cdot \beta_j(t)}$$

  
  -  Lets compute $\alpha$  at  time  $t = 0$,
$$\alpha_i(1) = P(\ Y_1 = y_1, X_1 = i \ | \ \theta \ )= \pi_i \cdot b_i(y_1)$$

-  Similarly for computing  $\alpha$  at time  $t = t + 1$,$$ 
\begin{split}
\alpha_j(t + 1) &= P(Y_1 = y_1, Y_2 = y_2,\ ....\ ,Y_{t + 1},\ X_{t + 1} = j \ | \ \theta \ )\\\\
&= \sum\limits_{i=1}^N \alpha_i(t) \cdot a_{ij} \cdot b_j(y_{t+1})\\\\
& \boxed{\alpha_j(t + 1) = b_j(y_{t+1}) \cdot \sum\limits_{i=1}^N \alpha_i(t) \cdot a_{ij}}
\end{split}
$$
$$$$
$i$   is previous state from which it transitioned to state  $j$  . So above we used the previous state $\alpha_i(t)$ ,  $a_{ij}$  i.e. state transition probability and  $b_j(y_{t+1})$ i.e. emission probability  over all previous $N$ states to get  $\alpha_j(t+1)$ .


-  Lets compute $\beta$  at time $t = T$,
  $$
  \begin{split}
  \beta_i(T) &= P(Y_{T+1} = y_{T+1},\ ...., Y_{T^2} \ | X_T = i, \theta)\\\\ 
  &= P(\ null \ sequence \ | X_T = i, \theta)\\\\
  \beta_i(T) &= 1
  \end{split}
  $$

  -  Similarly we calculate $\beta$  at time $t = t$,
$$
\boxed{\beta_i(t) = \sum\limits_{j =1}^N \beta_j(t + 1) \cdot a_{ij} \cdot b_j(y_{t+1})}
$$
$j$  is the next state  from which $i$  transitions to.  In the above equation you can see that $\beta_j(t+1)$ is used to calculate $\beta_i(t)$  so it is clear that we are moving backwards. 
$a_{ij}$  is the transition probability and $b_j(y_{t+1})$  is the emission probability, we multiply these terms over all $N$ next states.


-  After calculating $\alpha$  and  $\beta$  we have to re-estimate the values of $a_{ij}$  and  $b_j(y_t)$ . For that we have to calculate $P(X_t = i \ | \ Y, \theta)$  and $P(X_t = i, X_{t+1} = j \ | \ Y, \theta)$  for the emission and transition probabilities respectively. 

-  We name these probabilities as,
$$\boxed{\gamma_i(t) = P( \ X_t = i \ |\ Y, \theta \ )}$$
$$\boxed {\zeta_{ij}(t) = P(\ X_t = i, X_{t+1} = j \ |\ Y, \theta)}$$
-  **$\gamma _i(t)$  is the probability of being in state $i$  at time  $t$  given the observation $Y$ and parameters  $\theta$.**
- **$\zeta_{ij}(t)$  is the probability of being in state $i$  and state $j$  at time $t$  and $t+1$  respectively given the observation $Y$ and parameters $\theta$.**

-  Now we have to find these probabilities using $\alpha$  and  $\beta$ .

$$\gamma_i(t) =  P( \ X_t = i \ |\ Y, \theta \ ) = \frac{P(X_t = i \ \cap Y \ \cap \ \theta)}{P(\ Y \ \cap \ \theta)} = \frac{P(X_t = i ,\ Y \ | \ \theta)}{P( \ Y \ | \ \theta)}$$
$$P(Y \ |\ \theta) =Normalizing \ factor$$
-  We already know that,
  $$\frac{P(X_t = i \ , Y \ | \ \theta)}{\sum\limits_{j = 1}^{N} P(X_t = j \ , \ Y, \ | \ \theta)} = \frac{\alpha_i(t) \cdot  \beta_i(t)}{\sum\limits_{j=1}^N \alpha_j(t) \cdot \beta_j(t)}$$
-  Therefore,
$$\boxed {\gamma_i(t) = \frac{\alpha_i(t) \cdot  \beta_i(t)}{\sum\limits_{j=1}^N \alpha_j(t) \cdot \beta_j(t)}}$$
 
  
  -  Lets follow the same steps to get $\zeta_{ij}(t)$  as well,
$$
\begin{split}
\zeta_{ij}(t) &= P(\ X_t = i, X_{t+1} = j \ |\ Y, \theta)\\\\
&= \frac{P(X_t = i \ \cap X_{t+1} = j \ \cap \ Y \ \cap \ \theta)}{P(Y \ \cap \ \theta)}\\\\
&= \frac{P(\ X_t = i, X_{t+1} = j, \ Y \ | \ \theta)}{P(\ Y \ | \ \theta)}
\end{split}
$$
$$P(Y \ | \ \theta) = Normalizing \ Factor$$


-  We can write $P(\ X_t = i, X_{t+1} = j, \ Y \ | \ \theta)$   as multiplication of 
	1.  $\alpha_i(t)$    i.e.    $P(\ Y_1 = y_1, \ Y_2 = y_2 \ ...\ Y_t = y_t, \ X_t = i \ |\ \theta \ )$
	2. $\beta_j(t + 1)$    i.e.    $P(\ Y_{t+1} = y_{t+1} ,\ ...,\ Y_{T-1} = y_{T-1} ,\ Y_T = y_T\ |\ X_t = i ,\ \theta \ )$
	3.  $a_{ij}$    i.e.    $P(X_{t+1} = j \ |\  X_t = i, \ \theta)$
	4.  $b_j(y_{t+1})$    i.e.    $P(Y_{t+1} = y_{t+1} \ | \ X_{t+1} = j, \ \theta)$

-  And we can normalize the above term by the summation of all the possible next and current POS tags denoted by  $i$  and  $j$.
$$Normalizing \ Factor = \sum\limits_{i}\sum\limits_{j} \alpha_i(t) \cdot \beta_j(t + 1) \cdot a_{ij} \cdot b_j(y_{t+1})$$
- So finally we get,
$$\boxed{\zeta_{ij}(t) = \frac{\alpha_i(t) \cdot \beta_j(t + 1) \cdot a_{ij} \cdot b_j(y_{t+1})}{\sum\limits_{i}\sum\limits_{j} \alpha_i(t) \cdot \beta_j(t + 1) \cdot a_{ij} \cdot b_j(y_{t+1})}}$$

#### Re-estimation of Parameters
-  After finding  $\gamma$   and  $\zeta$  ,  we can  re-estimate our parameter  $\theta = (A, B, \pi)$  using these new computed probabilities.
	1.  Probability that a state occurs at the start of sentence or at time $t = 1$ .
	   $$\boxed{\pi_i = \gamma_i(1)}$$
	2.  Transition Probabilities i.e. expected no. of of transitions from  state  $i$  to state  $j$   compared to total no. of transitions away from state  $i$ .
	  $$\boxed{a_{ij} = \frac{\sum\limits_{t = 1}^T \zeta_{ij}(t)}{\sum\limits_{t = 1}^T \gamma_{i}(t)}}$$
	  3.  Emission Probabilities  i.e.  expected no. of times the output observations are for say  $v_k$  while being in state  $i$  compared to expected total no. of times in state  $i$ occurred.
	  $$\boxed{b_i(v_k) = \frac{\sum\limits_{t = 1}^T \ 1_{y_t = v_k}\cdot \gamma_{i}(t)}{\sum\limits_{t = 1}^T \gamma_{i}(t)}}$$
	  Here  $1_{y_t = v_k}$  is an indicator function i.e.  only for the condition it will output  $1$   otherwise it will output $0$ . 

-  After re-estimation you get the new parameter $\overset{-}{\theta} = (\overset{-}{A}, \overset{-}{B}, \overset{-}{\pi})$ and then you repeat all the previous steps until the resulting probabilities converge satisfactorily i.e.  not much change is seen  after intervals.

![[Pasted image 20230703144228.png]]


### Issues of Markov Model Training
-  **Unknown Words**: 
	- We do not have the required probabilities for unknown words during the runtime.
	- *Possible Solution:*  Use morphological cues (capitalization, suffix) to assign a more calculated guess. For Eg:   "$Yash$" may not occur in training corpus but one can determine that it is a proper noun by observing the first character of the word.

- **Limited Context:**
	-  Previously we used First order Hidden Markov Model for getting the sequence of tags but the transition probabilities are only dependent on the previous tag which causes problems like,
		- "$is \ clearly \ marked$"  --->  the tag of  $marked$ will be $verb, \ past \ participle$ .
		- "$he \ clearly \ marked$"  ---->  the tag of  $marked$  in this case will be $verb, \ past \ tense$ .
		-  Whereas we had used a First Order HMM  then the tag would have been same for both the sentence as the context word is just the previous word i.e. $clearly$. which is same in both the phrases.
	- *Possible Solution*:  Use higher order model, combine various N-gram models to avoid sparseness problems i.e. not finding any occurrences of N-gram or phrases of particular sequence in that case choose a lower N-gram model.  

- Limited set of features:
	- We cannot use features other than probability of tag given the previous tag  and probability of word given the tag.
	- For Eg:  
		- Probability of word ending with "$ed$"  given the previous word.


-  Therefore we move to Maximum Entropy Model [[4.  Maximum Entropy Model for POS tagging]] 